%!TEX TS-program = xelatex 
%!TEX encoding = UTF-8 Unicode 
% Use Xelatex and UTF-8 

\documentclass[ENG]{Sketch} 
% 用这一句引用SealZhang类 选项不填默认英文 可以写[ENG]或者[CHN]  

\title{Assignment \#3 for CS224n} 
\author{Zhang Chuheng \\ \href{mailto:zhangchuheng123@live.com}{zhangchuheng123@live.com}} 
\date{\today}  

\begin{document}  
\maketitle 

See details of Assignment \#3 \href{http://web.stanford.edu/class/cs224n/assignment3/index.html}{here}.

\section{A Window into NER}

\subsection{Written Answer a.}

\subsubsection{Ambiguous Sentences}

\begin{enumerate}
\item \emph{Wilson announced a multi-year partnership with Junior Tennis Champions Center.} 

Wilson could either be a person named Wilson, or a company.

\item \emph{James likes shopping for clothes in Jack and Jones.}

\emph{Jack and Jones} is easily misclassified to PER, though it is a ORG. 

\end{enumerate}

\subsubsection{Why might it be important to use features apart from the word itself to predict
named entity labels?}

Sometimes it is hard to distinguish what does the phrase mean simply from the phrase itself. As is shown in the previous answer, there might be ambiguities. We need to use context or casing to decide which class the named entity belongs to.

\subsubsection{Describe at least two features (apart from the word) that would help in predicting
whether a word is part of a named entity or not.}

Casing and context (eg. relative verbs).

\subsection{Written Answer b.}

\subsubsection{Dimensions}

Assuming the vectors are represented as row vector.

$$
\being{aligned}
\bm{e}^{(t)} & \rightarrow 1 \times (2w+1)D \\
W & \rightarrow (2w+1)D \times H \\
U & \rightarrow H \times C 
\end{aligned}
$$

\subsection{Computation Complexity}

$$
\being{aligned}
\bm{e}^{(t)} & \rightarrow O((2w+1)D) \\
\bm{h}^{(t)} & \rightarrow O((2w+1)DH + H) \\
\bm{\hat{y}}^{(t)} & \rightarrow O(HC+C) 
\end{aligned}
$$

The complexity in total is $O((2w+1)DHT+HCT)$, where $T$ is the number of words.

\subsection{Programming}

\section{RNN for NER}

\subsection{Written Answer a.}

\subsection{How many more parameters does the RNN model in comparison to the window-based model?}

There's one more parameter $W_h \in \mathbb{R}^{H \tiems H}$. Besides, the parameter $W_x \in \mathbb{R}^{D \tiems H}$ instead of $\mathbb{R}^{(2w+1)D \tiems H}$.

\subsection{What is the computational complexity of predicting labels for a sentence of length
T (for the RNN model)?}

$$
\being{aligned}
\bm{e}^{(t)} & \rightarrow O(D) \\
\bm{h}^{(t)} & \rightarrow O(H^2 + HD + H) \\
\bm{\hat{y}}^{(t)} & \rightarrow O(HC+C) 
\end{aligned}
$$

The complexity in total is $O((H^2+HD+HC)T)$, where $T$ is corpus size.

\subsection{Written Answer b.}

\subsubsection{Inconsistency of CE and $F_1$}



\section{Appendix}

\lstinputlisting[language=Python, caption={q1\_softmax.py (This shows the basic usage of TensorFlow.) }]{code/q1_softmax.py}

\end{document} 
 














